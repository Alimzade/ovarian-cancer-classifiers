{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this notebook we use a dictionary of extracted features from *main3.ipynb*, where width and height was divided by 5\n",
    "* Here more data were passed from Test set to Train set, resulting in 10% increase in accuracy on WSI images (`80%`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/root/ubc_ocean/anar/extracted-features/main3_512px_resnet101_200.pkl', 'rb') as f:\n",
    "    slide_features = pickle.load(f)\n",
    "    \n",
    "len(slide_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train balance: {'LGSC': 32, 'EC': 32, 'CC': 32, 'HGSC': 32, 'MC': 32}\n",
      "Validation balance: {'HGSC': 4, 'MC': 4, 'EC': 4, 'LGSC': 4, 'CC': 4}\n",
      "Test balance: {'MC': 4, 'EC': 4, 'LGSC': 4, 'CC': 4, 'HGSC': 4}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "# Set a fixed random state for reproducibility\n",
    "random_state = 33\n",
    "\n",
    "# Convert slide_features to a suitable format\n",
    "data = [(features['features'], features['label']) for path, features in slide_features.items()]\n",
    "\n",
    "# Organize data by labels\n",
    "data_by_label = defaultdict(list)\n",
    "for features, label in data:\n",
    "    data_by_label[label].append((features, label))\n",
    "\n",
    "# Split data for each label into train, validation, and test\n",
    "train_data = []\n",
    "val_data = []\n",
    "test_data = []\n",
    "\n",
    "for label, label_data in data_by_label.items():\n",
    "    # Split data for this label into train and test with a fixed random state\n",
    "    train_val_label_data, test_label_data = train_test_split(label_data, test_size=0.10, random_state=random_state)\n",
    "    \n",
    "    # Split train data into train and validation with a fixed random state\n",
    "    train_label_data, val_label_data = train_test_split(train_val_label_data, test_size=0.1, random_state=random_state)  # 0.25 x 0.8 = 0.2 of original\n",
    "    \n",
    "    # Append split data to respective sets\n",
    "    train_data.extend(train_label_data)\n",
    "    val_data.extend(val_label_data)\n",
    "    test_data.extend(test_label_data)\n",
    "\n",
    "# Shuffle the datasets\n",
    "random.seed(random_state)\n",
    "random.shuffle(train_data)\n",
    "random.shuffle(val_data)\n",
    "random.shuffle(test_data)\n",
    "\n",
    "# Function to check balance in each set\n",
    "def check_balance(dataset):\n",
    "    label_counts = defaultdict(int)\n",
    "    for _, label in dataset:\n",
    "        label_counts[label] += 1\n",
    "    return dict(label_counts)\n",
    "\n",
    "# Display balance of each set\n",
    "print(\"Train balance:\", check_balance(train_data))\n",
    "print(\"Validation balance:\", check_balance(val_data))\n",
    "print(\"Test balance:\", check_balance(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from label strings to integers\n",
    "unique_labels = sorted(set(label for _, label in data))\n",
    "label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "class MILDataset(Dataset):\n",
    "    def __init__(self, data, label_to_idx):\n",
    "        self.data = data\n",
    "        self.label_to_idx = label_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature_vectors, label = self.data[idx]\n",
    "        label_idx = self.label_to_idx[label]  # Convert label to integer\n",
    "        return torch.tensor(feature_vectors), torch.tensor(label_idx, dtype=torch.float32)\n",
    "\n",
    "# Create Datasets for train, validation, and test\n",
    "train_dataset = MILDataset(train_data, label_to_idx)\n",
    "val_dataset = MILDataset(val_data, label_to_idx)\n",
    "test_dataset = MILDataset(test_data, label_to_idx)\n",
    "\n",
    "# Create DataLoaders for each set\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Train Loss: 1.6114, Train Acc: 18.24%, Validation Loss: 1.5640, Val Acc: 50.00%\n",
      "Epoch 2/15, Train Loss: 1.5170, Train Acc: 33.33%, Validation Loss: 1.4260, Val Acc: 50.00%\n",
      "Epoch 3/15, Train Loss: 1.3571, Train Acc: 40.25%, Validation Loss: 1.2833, Val Acc: 40.00%\n",
      "Epoch 4/15, Train Loss: 1.1448, Train Acc: 61.01%, Validation Loss: 1.1208, Val Acc: 60.00%\n",
      "Epoch 5/15, Train Loss: 0.9701, Train Acc: 65.41%, Validation Loss: 0.9738, Val Acc: 70.00%\n",
      "Epoch 6/15, Train Loss: 0.7930, Train Acc: 73.58%, Validation Loss: 0.8247, Val Acc: 80.00%\n",
      "Epoch 7/15, Train Loss: 0.6699, Train Acc: 77.99%, Validation Loss: 0.7731, Val Acc: 75.00%\n",
      "Epoch 8/15, Train Loss: 0.5448, Train Acc: 82.39%, Validation Loss: 0.7732, Val Acc: 75.00%\n",
      "Epoch 9/15, Train Loss: 0.4730, Train Acc: 87.42%, Validation Loss: 0.8031, Val Acc: 75.00%\n",
      "Epoch 10/15, Train Loss: 0.4041, Train Acc: 88.05%, Validation Loss: 0.7058, Val Acc: 85.00%\n",
      "Epoch 11/15, Train Loss: 0.3201, Train Acc: 94.34%, Validation Loss: 0.7301, Val Acc: 85.00%\n",
      "Epoch 12/15, Train Loss: 0.2325, Train Acc: 93.71%, Validation Loss: 0.6632, Val Acc: 85.00%\n",
      "Epoch 13/15, Train Loss: 0.2025, Train Acc: 94.97%, Validation Loss: 0.6887, Val Acc: 80.00%\n",
      "Epoch 14/15, Train Loss: 0.1498, Train Acc: 97.48%, Validation Loss: 0.7251, Val Acc: 80.00%\n",
      "Epoch 00015: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 15/15, Train Loss: 0.1125, Train Acc: 97.48%, Validation Loss: 0.7668, Val Acc: 75.00%\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "class AttentionMIL(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super(AttentionMIL, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Softmax(dim=0)\n",
    "        )\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, bag):\n",
    "        h = torch.relu(self.fc1(bag))\n",
    "        a = self.attention(h)\n",
    "        v = torch.sum(a * h, dim=0)\n",
    "        y = self.classifier(v)\n",
    "        return y, a\n",
    "\n",
    "# Number of unique classes\n",
    "num_classes = len(unique_labels)\n",
    "\n",
    "model = AttentionMIL(input_dim=2048, hidden_dim=256, num_classes=num_classes)\n",
    "loss_function = nn.CrossEntropyLoss()  # CrossEntropyLoss for multiclass\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "\n",
    "# Early Stopping Parameters\n",
    "best_val_loss = float('inf')\n",
    "patience = 4\n",
    "patience_counter = 0\n",
    "\n",
    "# Model Training with Validation\n",
    "num_epochs = 15\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    # Training loop\n",
    "    for bags, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if bags.nelement() == 0:  # Check if the bag is empty\n",
    "            continue\n",
    "\n",
    "        #print(\"Bags shape:\", bags.shape)  # Add this line for debugging\n",
    "        #print(\"Labels shape:\", labels.shape)  # Add this line for debugging\n",
    "\n",
    "        # Select the first bag in the batch\n",
    "        bags = bags[0]  # bags now has the shape [75, 2048]\n",
    "        # For labels, the following line should work fine\n",
    "        labels = labels.squeeze(0).long()\n",
    "    \n",
    "        output, _ = model(bags)\n",
    "        loss = loss_function(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 0)\n",
    "        train_total += 1\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_accuracy = 100 * train_correct / train_total\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for bags, labels in val_loader:\n",
    "            if bags.nelement() == 0:  # Check if the bag is empty\n",
    "                continue\n",
    "\n",
    "            bags = bags.squeeze(0)\n",
    "            labels = labels.squeeze(0).long()\n",
    "            output, _ = model(bags)\n",
    "            loss = loss_function(output, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 0)\n",
    "            val_total += 1\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    val_loss /= len(val_loader)\n",
    "    \n",
    "    # Step the scheduler\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Stopping early due to no improvement in validation loss.\")\n",
    "        break\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Validation Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8000\n",
      "Precision: 0.8476\n",
      "Recall: 0.8000\n",
      "F1 Score: 0.8026\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for bags, labels in test_loader:\n",
    "        output, _ = model(bags.squeeze(0))\n",
    "        _, predicted_labels = torch.max(output, 0)  # Get the index of the max log-probability\n",
    "        predictions.append(predicted_labels.item())  # Append scalar value\n",
    "        true_labels.append(labels.squeeze(0).item())  # Append scalar value\n",
    "\n",
    "# Convert lists to arrays for metric calculation\n",
    "predictions = np.array(predictions)\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "precision = precision_score(true_labels, predictions, average='macro', zero_division=1)\n",
    "recall = recall_score(true_labels, predictions, average='macro')\n",
    "f1 = f1_score(true_labels, predictions, average='macro')\n",
    "\n",
    "# Print the metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MC', 'EC', 'MC', 'MC', 'LGSC', 'CC', 'LGSC', 'HGSC', 'HGSC', 'LGSC', 'CC', 'EC', 'HGSC', 'CC', 'HGSC', 'EC', 'HGSC', 'HGSC', 'LGSC', 'HGSC']\n",
      "['MC', 'EC', 'MC', 'MC', 'LGSC', 'CC', 'LGSC', 'EC', 'EC', 'LGSC', 'CC', 'EC', 'HGSC', 'CC', 'HGSC', 'MC', 'HGSC', 'HGSC', 'LGSC', 'CC']\n"
     ]
    }
   ],
   "source": [
    "idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "\n",
    "# Use idx_to_label to map numeric predictions back to label names\n",
    "predicted_labels = [idx_to_label[int(idx)] for idx in predictions]\n",
    "true_label_names = [idx_to_label[int(idx)] for idx in true_labels]\n",
    "\n",
    "# Now predicted_labels and true_label_names contain the label names\n",
    "print(predicted_labels)\n",
    "print(true_label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the model and load in kaggle submission notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/main4_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = AttentionMIL(input_dim=2048, hidden_dim=256, num_classes=num_classes)\n",
    "model2.load_state_dict(torch.load('/root/ubc_ocean/anar/models/main4_model.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
