{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, save_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_tma_dir = '../TMA_images'\n",
    "augmented_tma_dir = './augmented-tma-2'\n",
    "\n",
    "# Update the original_tma_dir to point to the directory with extracted TMA images\n",
    "original_tma_dir = os.path.join(extracted_tma_dir, 'train_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_tma = pd.read_csv(\"./augmented-tma/combined_tma.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'image_id' column to string type\n",
    "combined_tma['image_id'] = combined_tma['image_id'].astype(str)\n",
    "\n",
    "# Separate original images from augmented ones\n",
    "original_images = combined_tma[~combined_tma['image_id'].str.contains('_')]\n",
    "augmented_images = combined_tma[combined_tma['image_id'].str.contains('_')]\n",
    "\n",
    "# Ensure balanced selection of original images for the test set\n",
    "# Here, we ensure we select at least one image from each class\n",
    "test_orig = original_images.groupby('label').sample(n=1, random_state=42)\n",
    "\n",
    "# Add augmented versions of these selected originals to the test set\n",
    "test_aug = augmented_images[augmented_images['image_id'].str.split('_').str[0].isin(test_orig['image_id'])]\n",
    "test_set = pd.concat([test_orig, test_aug])\n",
    "\n",
    "# The training set consists of all images not in the test set\n",
    "train_set = combined_tma[~combined_tma['image_id'].isin(test_set['image_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label to index mapping\n",
    "label_to_idx = {label: idx for idx, label in enumerate(train_set['label'].unique())}\n",
    "\n",
    "# Apply this mapping to your train and test sets\n",
    "train_set['label_idx'] = train_set['label'].map(label_to_idx)\n",
    "test_set['label_idx'] = test_set['label'].map(label_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class TissueDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx]['path']\n",
    "        image = Image.open(img_path)\n",
    "        label = self.dataframe.iloc[idx]['label_idx']\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse mapping from index to original label\n",
    "idx_to_label = {idx: label for label, idx in label_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate_fold(model, test_loader, label_to_idx):\n",
    "    model.eval()\n",
    "    predictions, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            actuals.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Convert indices back to original labels\n",
    "    predicted_labels = [idx_to_label[idx] for idx in predictions]\n",
    "    actual_labels = [idx_to_label[idx] for idx in actuals]\n",
    "\n",
    "    # Calculate metrics\n",
    "    fold_metrics = {}\n",
    "    fold_metrics['classification_report'] = classification_report(actual_labels, predicted_labels, zero_division=0)\n",
    "    fold_metrics['confusion_matrix'] = confusion_matrix(actual_labels, predicted_labels)\n",
    "\n",
    "    return fold_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_fold_results(fold_results):\n",
    "    # Aggregate results from all folds\n",
    "    # You can customize this function based on how you want to aggregate\n",
    "    # For simplicity, this example just collects all reports in a list\n",
    "    aggregated_results = {\n",
    "        'classification_reports': [fold['classification_report'] for fold in fold_results],\n",
    "        'confusion_matrices': [fold['confusion_matrix'] for fold in fold_results]\n",
    "    }\n",
    "    return aggregated_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4, Loss: 1.4053477048873901\n",
      "Epoch 2/4, Loss: 0.5859560966491699\n",
      "Epoch 3/4, Loss: 0.08491836488246918\n",
      "Epoch 4/4, Loss: 0.005249147769063711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       1.00      1.00      1.00        11\n",
      "          EC       0.92      1.00      0.96        11\n",
      "        HGSC       0.55      1.00      0.71        11\n",
      "        LGSC       0.00      0.00      0.00        11\n",
      "          MC       0.83      0.91      0.87        11\n",
      "\n",
      "    accuracy                           0.78        55\n",
      "   macro avg       0.66      0.78      0.71        55\n",
      "weighted avg       0.66      0.78      0.71        55\n",
      "\n",
      "Epoch 1/4, Loss: 1.311478853225708\n",
      "Epoch 2/4, Loss: 0.6833809614181519\n",
      "Epoch 3/4, Loss: 0.15726317465305328\n",
      "Epoch 4/4, Loss: 0.010780763812363148\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       1.00      1.00      1.00        11\n",
      "          EC       0.31      0.45      0.37        11\n",
      "        HGSC       0.41      1.00      0.58        11\n",
      "        LGSC       1.00      0.09      0.17        11\n",
      "          MC       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.51        55\n",
      "   macro avg       0.54      0.51      0.42        55\n",
      "weighted avg       0.54      0.51      0.42        55\n",
      "\n",
      "Epoch 1/4, Loss: 1.5174683332443237\n",
      "Epoch 2/4, Loss: 0.8381179571151733\n",
      "Epoch 3/4, Loss: 0.18002988398075104\n",
      "Epoch 4/4, Loss: 0.05779724195599556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.48      1.00      0.65        11\n",
      "          EC       0.92      1.00      0.96        11\n",
      "        HGSC       1.00      1.00      1.00        11\n",
      "        LGSC       0.00      0.00      0.00        11\n",
      "          MC       1.00      0.82      0.90        11\n",
      "\n",
      "    accuracy                           0.76        55\n",
      "   macro avg       0.68      0.76      0.70        55\n",
      "weighted avg       0.68      0.76      0.70        55\n",
      "\n",
      "Epoch 1/4, Loss: 1.2860088348388672\n",
      "Epoch 2/4, Loss: 0.427342027425766\n",
      "Epoch 3/4, Loss: 0.05140260234475136\n",
      "Epoch 4/4, Loss: 0.009022262878715992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.79      1.00      0.88        11\n",
      "          EC       0.65      1.00      0.79        11\n",
      "        HGSC       0.52      1.00      0.69        11\n",
      "        LGSC       0.00      0.00      0.00        11\n",
      "          MC       1.00      0.27      0.43        11\n",
      "\n",
      "    accuracy                           0.65        55\n",
      "   macro avg       0.59      0.65      0.56        55\n",
      "weighted avg       0.59      0.65      0.56        55\n",
      "\n",
      "Epoch 1/4, Loss: 1.2345227003097534\n",
      "Epoch 2/4, Loss: 0.638946533203125\n",
      "Epoch 3/4, Loss: 0.23977096378803253\n",
      "Epoch 4/4, Loss: 0.00910940207540989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       1.00      0.64      0.78        11\n",
      "          EC       1.00      0.91      0.95        11\n",
      "        HGSC       1.00      1.00      1.00        11\n",
      "        LGSC       0.00      0.00      0.00        11\n",
      "          MC       0.41      1.00      0.58        11\n",
      "\n",
      "    accuracy                           0.71        55\n",
      "   macro avg       0.68      0.71      0.66        55\n",
      "weighted avg       0.68      0.71      0.66        55\n",
      "\n",
      "Classification Report for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       1.00      1.00      1.00        11\n",
      "          EC       0.92      1.00      0.96        11\n",
      "        HGSC       0.55      1.00      0.71        11\n",
      "        LGSC       0.00      0.00      0.00        11\n",
      "          MC       0.83      0.91      0.87        11\n",
      "\n",
      "    accuracy                           0.78        55\n",
      "   macro avg       0.66      0.78      0.71        55\n",
      "weighted avg       0.66      0.78      0.71        55\n",
      "\n",
      "\n",
      "Classification Report for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       1.00      1.00      1.00        11\n",
      "          EC       0.31      0.45      0.37        11\n",
      "        HGSC       0.41      1.00      0.58        11\n",
      "        LGSC       1.00      0.09      0.17        11\n",
      "          MC       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.51        55\n",
      "   macro avg       0.54      0.51      0.42        55\n",
      "weighted avg       0.54      0.51      0.42        55\n",
      "\n",
      "\n",
      "Classification Report for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.48      1.00      0.65        11\n",
      "          EC       0.92      1.00      0.96        11\n",
      "        HGSC       1.00      1.00      1.00        11\n",
      "        LGSC       0.00      0.00      0.00        11\n",
      "          MC       1.00      0.82      0.90        11\n",
      "\n",
      "    accuracy                           0.76        55\n",
      "   macro avg       0.68      0.76      0.70        55\n",
      "weighted avg       0.68      0.76      0.70        55\n",
      "\n",
      "\n",
      "Classification Report for Fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.79      1.00      0.88        11\n",
      "          EC       0.65      1.00      0.79        11\n",
      "        HGSC       0.52      1.00      0.69        11\n",
      "        LGSC       0.00      0.00      0.00        11\n",
      "          MC       1.00      0.27      0.43        11\n",
      "\n",
      "    accuracy                           0.65        55\n",
      "   macro avg       0.59      0.65      0.56        55\n",
      "weighted avg       0.59      0.65      0.56        55\n",
      "\n",
      "\n",
      "Classification Report for Fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       1.00      0.64      0.78        11\n",
      "          EC       1.00      0.91      0.95        11\n",
      "        HGSC       1.00      1.00      1.00        11\n",
      "        LGSC       0.00      0.00      0.00        11\n",
      "          MC       0.41      1.00      0.58        11\n",
      "\n",
      "    accuracy                           0.71        55\n",
      "   macro avg       0.68      0.71      0.66        55\n",
      "weighted avg       0.68      0.71      0.66        55\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Assuming combined_tma is your complete dataset\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Placeholder for fold results\n",
    "fold_results = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for train_index, test_index in kfold.split(combined_tma):\n",
    "    # Split data into training and testing sets for this fold\n",
    "    train_fold, test_fold = combined_tma.iloc[train_index], combined_tma.iloc[test_index]\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = TissueDataset(train_set, transform=transform)\n",
    "    test_dataset = TissueDataset(test_set, transform=transform)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "    # Load a pre-trained model\n",
    "    model = timm.create_model('resnet50', pretrained=True)\n",
    "\n",
    "    # Modify the classifier\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 5)\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    num_epochs = 4\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            actuals.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Convert indices back to original labels\n",
    "    predicted_labels = [idx_to_label[idx] for idx in predictions]\n",
    "    actual_labels = [idx_to_label[idx] for idx in actuals]\n",
    "\n",
    "    print(classification_report(actual_labels, predicted_labels, zero_division=0))\n",
    "\n",
    "    # Evaluate the model for this fold\n",
    "    fold_metrics = evaluate_fold(model, test_loader, label_to_idx)\n",
    "    fold_results.append(fold_metrics)\n",
    "\n",
    "# Aggregate results from all folds\n",
    "overall_results = aggregate_fold_results(fold_results)\n",
    "\n",
    "for i, report in enumerate(overall_results['classification_reports']):\n",
    "    print(f\"Classification Report for Fold {i+1}:\\n{report}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       1.00      1.00      1.00        11\n",
      "          EC       0.92      1.00      0.96        11\n",
      "        HGSC       0.55      1.00      0.71        11\n",
      "        LGSC       0.00      0.00      0.00        11\n",
      "          MC       0.83      0.91      0.87        11\n",
      "\n",
      "    accuracy                           0.78        55\n",
      "   macro avg       0.66      0.78      0.71        55\n",
      "weighted avg       0.66      0.78      0.71        55\n",
      "\n",
      "\n",
      "Classification Report for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       1.00      1.00      1.00        11\n",
      "          EC       0.31      0.45      0.37        11\n",
      "        HGSC       0.41      1.00      0.58        11\n",
      "        LGSC       1.00      0.09      0.17        11\n",
      "          MC       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.51        55\n",
      "   macro avg       0.54      0.51      0.42        55\n",
      "weighted avg       0.54      0.51      0.42        55\n",
      "\n",
      "\n",
      "Classification Report for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.48      1.00      0.65        11\n",
      "          EC       0.92      1.00      0.96        11\n",
      "        HGSC       1.00      1.00      1.00        11\n",
      "        LGSC       0.00      0.00      0.00        11\n",
      "          MC       1.00      0.82      0.90        11\n",
      "\n",
      "    accuracy                           0.76        55\n",
      "   macro avg       0.68      0.76      0.70        55\n",
      "weighted avg       0.68      0.76      0.70        55\n",
      "\n",
      "\n",
      "Classification Report for Fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.79      1.00      0.88        11\n",
      "          EC       0.65      1.00      0.79        11\n",
      "        HGSC       0.52      1.00      0.69        11\n",
      "        LGSC       0.00      0.00      0.00        11\n",
      "          MC       1.00      0.27      0.43        11\n",
      "\n",
      "    accuracy                           0.65        55\n",
      "   macro avg       0.59      0.65      0.56        55\n",
      "weighted avg       0.59      0.65      0.56        55\n",
      "\n",
      "\n",
      "Classification Report for Fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       1.00      0.64      0.78        11\n",
      "          EC       1.00      0.91      0.95        11\n",
      "        HGSC       1.00      1.00      1.00        11\n",
      "        LGSC       0.00      0.00      0.00        11\n",
      "          MC       0.41      1.00      0.58        11\n",
      "\n",
      "    accuracy                           0.71        55\n",
      "   macro avg       0.68      0.71      0.66        55\n",
      "weighted avg       0.68      0.71      0.66        55\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, report in enumerate(overall_results['classification_reports']):\n",
    "    print(f\"Classification Report for Fold {i+1}:\\n{report}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average of cross-validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EC</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HGSC</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGSC</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MC</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Macro Avg</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Weighted Avg</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Class  Precision  Recall  F1-Score\n",
       "0            CC       0.85    0.93      0.86\n",
       "1            EC       0.76    0.87      0.81\n",
       "2          HGSC       0.70    1.00      0.80\n",
       "3          LGSC       0.20    0.02      0.03\n",
       "4            MC       0.65    0.60      0.56\n",
       "5     Macro Avg       0.63    0.68      0.61\n",
       "6  Weighted Avg       0.63    0.68      0.61"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-import necessary library after reset\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare data for DataFrame\n",
    "data = {\n",
    "    \"Class\": [\"CC\", \"EC\", \"HGSC\", \"LGSC\", \"MC\", \"Macro Avg\", \"Weighted Avg\"],\n",
    "    \"Precision\": [0.85, 0.76, 0.70, 0.20, 0.65, 0.63, 0.63],\n",
    "    \"Recall\": [0.93, 0.87, 1.00, 0.02, 0.60, 0.68, 0.68],\n",
    "    \"F1-Score\": [0.86, 0.81, 0.80, 0.03, 0.56, 0.61, 0.61],\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame as a table\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "## WHAT TO DO?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Use a different ImageDataGenerator for `LGSC` class\n",
    "#### 2. Use Ensemble of Methods "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Baku",
   "language": "python",
   "name": "baku"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
