{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we extract features from TMA patches (original + augmented)\n",
    "Goal is to test MIL classifier, but code not working properly for model training part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import timm\n",
    "import pickle\n",
    "from PIL import Image, ImageFile\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_tma = pd.read_csv(\"/root/ubc_ocean/anar/augmented-tma/combined_tma.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "      <th>is_tma</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>3388</td>\n",
       "      <td>3388</td>\n",
       "      <td>True</td>\n",
       "      <td>TMA_images/train_images/91.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4134</td>\n",
       "      <td>MC</td>\n",
       "      <td>2964</td>\n",
       "      <td>2964</td>\n",
       "      <td>True</td>\n",
       "      <td>TMA_images/train_images/4134.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8280</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>2964</td>\n",
       "      <td>2964</td>\n",
       "      <td>True</td>\n",
       "      <td>TMA_images/train_images/8280.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9200</td>\n",
       "      <td>MC</td>\n",
       "      <td>3388</td>\n",
       "      <td>3388</td>\n",
       "      <td>True</td>\n",
       "      <td>TMA_images/train_images/9200.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13568</td>\n",
       "      <td>LGSC</td>\n",
       "      <td>2964</td>\n",
       "      <td>2964</td>\n",
       "      <td>True</td>\n",
       "      <td>TMA_images/train_images/13568.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>270</td>\n",
       "      <td>61797_6</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>3388</td>\n",
       "      <td>3388</td>\n",
       "      <td>True</td>\n",
       "      <td>anar/augmented-tma/61797_6.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>271</td>\n",
       "      <td>61797_7</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>3388</td>\n",
       "      <td>3388</td>\n",
       "      <td>True</td>\n",
       "      <td>anar/augmented-tma/61797_7.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>272</td>\n",
       "      <td>61797_8</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>3388</td>\n",
       "      <td>3388</td>\n",
       "      <td>True</td>\n",
       "      <td>anar/augmented-tma/61797_8.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>273</td>\n",
       "      <td>61797_9</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>3388</td>\n",
       "      <td>3388</td>\n",
       "      <td>True</td>\n",
       "      <td>anar/augmented-tma/61797_9.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>274</td>\n",
       "      <td>61797_10</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>3388</td>\n",
       "      <td>3388</td>\n",
       "      <td>True</td>\n",
       "      <td>anar/augmented-tma/61797_10.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  image_id label  image_width  image_height  is_tma  \\\n",
       "0             0        91  HGSC         3388          3388    True   \n",
       "1             1      4134    MC         2964          2964    True   \n",
       "2             2      8280  HGSC         2964          2964    True   \n",
       "3             3      9200    MC         3388          3388    True   \n",
       "4             4     13568  LGSC         2964          2964    True   \n",
       "..          ...       ...   ...          ...           ...     ...   \n",
       "270         270   61797_6  HGSC         3388          3388    True   \n",
       "271         271   61797_7  HGSC         3388          3388    True   \n",
       "272         272   61797_8  HGSC         3388          3388    True   \n",
       "273         273   61797_9  HGSC         3388          3388    True   \n",
       "274         274  61797_10  HGSC         3388          3388    True   \n",
       "\n",
       "                                  path  \n",
       "0       TMA_images/train_images/91.png  \n",
       "1     TMA_images/train_images/4134.png  \n",
       "2     TMA_images/train_images/8280.png  \n",
       "3     TMA_images/train_images/9200.png  \n",
       "4    TMA_images/train_images/13568.png  \n",
       "..                                 ...  \n",
       "270     anar/augmented-tma/61797_6.png  \n",
       "271     anar/augmented-tma/61797_7.png  \n",
       "272     anar/augmented-tma/61797_8.png  \n",
       "273     anar/augmented-tma/61797_9.png  \n",
       "274    anar/augmented-tma/61797_10.png  \n",
       "\n",
       "[275 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_tma['path'] = combined_tma['path'].str.replace('../', '')\n",
    "combined_tma['path'] = combined_tma['path'].str.replace('./', '')\n",
    "combined_tma['path'] = combined_tma['path'].str.replace('augmented-tma', 'anar/augmented-tma')\n",
    "combined_tma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dictionary of feature vector bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 1 of 275: /root/ubc_ocean/TMA_images/train_images/91.png\n",
      "Processing image 2 of 275: /root/ubc_ocean/TMA_images/train_images/4134.png\n",
      "Processing image 3 of 275: /root/ubc_ocean/TMA_images/train_images/8280.png\n",
      "Processing image 4 of 275: /root/ubc_ocean/TMA_images/train_images/9200.png\n",
      "Processing image 5 of 275: /root/ubc_ocean/TMA_images/train_images/13568.png\n",
      "Processing image 6 of 275: /root/ubc_ocean/TMA_images/train_images/17637.png\n",
      "Processing image 7 of 275: /root/ubc_ocean/TMA_images/train_images/21020.png\n",
      "Processing image 8 of 275: /root/ubc_ocean/TMA_images/train_images/29084.png\n",
      "Processing image 9 of 275: /root/ubc_ocean/TMA_images/train_images/31594.png\n",
      "Processing image 10 of 275: /root/ubc_ocean/TMA_images/train_images/35565.png\n",
      "Processing image 11 of 275: /root/ubc_ocean/TMA_images/train_images/36302.png\n",
      "Processing image 12 of 275: /root/ubc_ocean/TMA_images/train_images/36583.png\n",
      "Processing image 13 of 275: /root/ubc_ocean/TMA_images/train_images/36783.png\n",
      "Processing image 14 of 275: /root/ubc_ocean/TMA_images/train_images/37385.png\n",
      "Processing image 15 of 275: /root/ubc_ocean/TMA_images/train_images/40864.png\n",
      "Processing image 16 of 275: /root/ubc_ocean/TMA_images/train_images/41368.png\n",
      "Processing image 17 of 275: /root/ubc_ocean/TMA_images/train_images/41586.png\n",
      "Processing image 18 of 275: /root/ubc_ocean/TMA_images/train_images/42857.png\n",
      "Processing image 19 of 275: /root/ubc_ocean/TMA_images/train_images/44603.png\n",
      "Processing image 20 of 275: /root/ubc_ocean/TMA_images/train_images/47035.png\n",
      "Processing image 21 of 275: /root/ubc_ocean/TMA_images/train_images/48734.png\n",
      "Processing image 22 of 275: /root/ubc_ocean/TMA_images/train_images/50932.png\n",
      "Processing image 23 of 275: /root/ubc_ocean/TMA_images/train_images/53655.png\n",
      "Processing image 24 of 275: /root/ubc_ocean/TMA_images/train_images/57696.png\n",
      "Processing image 25 of 275: /root/ubc_ocean/TMA_images/train_images/61797.png\n",
      "Processing image 26 of 275: /root/ubc_ocean/anar/augmented-tma/91_1.png\n",
      "Processing image 27 of 275: /root/ubc_ocean/anar/augmented-tma/91_2.png\n",
      "Processing image 28 of 275: /root/ubc_ocean/anar/augmented-tma/91_3.png\n",
      "Processing image 29 of 275: /root/ubc_ocean/anar/augmented-tma/91_4.png\n",
      "Processing image 30 of 275: /root/ubc_ocean/anar/augmented-tma/91_5.png\n",
      "Processing image 31 of 275: /root/ubc_ocean/anar/augmented-tma/91_6.png\n",
      "Processing image 32 of 275: /root/ubc_ocean/anar/augmented-tma/91_7.png\n",
      "Processing image 33 of 275: /root/ubc_ocean/anar/augmented-tma/91_8.png\n",
      "Processing image 34 of 275: /root/ubc_ocean/anar/augmented-tma/91_9.png\n",
      "Processing image 35 of 275: /root/ubc_ocean/anar/augmented-tma/91_10.png\n",
      "Processing image 36 of 275: /root/ubc_ocean/anar/augmented-tma/4134_1.png\n",
      "Processing image 37 of 275: /root/ubc_ocean/anar/augmented-tma/4134_2.png\n",
      "Processing image 38 of 275: /root/ubc_ocean/anar/augmented-tma/4134_3.png\n",
      "Processing image 39 of 275: /root/ubc_ocean/anar/augmented-tma/4134_4.png\n",
      "Processing image 40 of 275: /root/ubc_ocean/anar/augmented-tma/4134_5.png\n",
      "Processing image 41 of 275: /root/ubc_ocean/anar/augmented-tma/4134_6.png\n",
      "Processing image 42 of 275: /root/ubc_ocean/anar/augmented-tma/4134_7.png\n",
      "Processing image 43 of 275: /root/ubc_ocean/anar/augmented-tma/4134_8.png\n",
      "Processing image 44 of 275: /root/ubc_ocean/anar/augmented-tma/4134_9.png\n",
      "Processing image 45 of 275: /root/ubc_ocean/anar/augmented-tma/4134_10.png\n",
      "Processing image 46 of 275: /root/ubc_ocean/anar/augmented-tma/8280_1.png\n",
      "Processing image 47 of 275: /root/ubc_ocean/anar/augmented-tma/8280_2.png\n",
      "Processing image 48 of 275: /root/ubc_ocean/anar/augmented-tma/8280_3.png\n",
      "Processing image 49 of 275: /root/ubc_ocean/anar/augmented-tma/8280_4.png\n",
      "Processing image 50 of 275: /root/ubc_ocean/anar/augmented-tma/8280_5.png\n",
      "Processing image 51 of 275: /root/ubc_ocean/anar/augmented-tma/8280_6.png\n",
      "Processing image 52 of 275: /root/ubc_ocean/anar/augmented-tma/8280_7.png\n",
      "Processing image 53 of 275: /root/ubc_ocean/anar/augmented-tma/8280_8.png\n",
      "Processing image 54 of 275: /root/ubc_ocean/anar/augmented-tma/8280_9.png\n",
      "Processing image 55 of 275: /root/ubc_ocean/anar/augmented-tma/8280_10.png\n",
      "Processing image 56 of 275: /root/ubc_ocean/anar/augmented-tma/9200_1.png\n",
      "Processing image 57 of 275: /root/ubc_ocean/anar/augmented-tma/9200_2.png\n",
      "Processing image 58 of 275: /root/ubc_ocean/anar/augmented-tma/9200_3.png\n",
      "Processing image 59 of 275: /root/ubc_ocean/anar/augmented-tma/9200_4.png\n",
      "Processing image 60 of 275: /root/ubc_ocean/anar/augmented-tma/9200_5.png\n",
      "Processing image 61 of 275: /root/ubc_ocean/anar/augmented-tma/9200_6.png\n",
      "Processing image 62 of 275: /root/ubc_ocean/anar/augmented-tma/9200_7.png\n",
      "Processing image 63 of 275: /root/ubc_ocean/anar/augmented-tma/9200_8.png\n",
      "Processing image 64 of 275: /root/ubc_ocean/anar/augmented-tma/9200_9.png\n",
      "Processing image 65 of 275: /root/ubc_ocean/anar/augmented-tma/9200_10.png\n",
      "Processing image 66 of 275: /root/ubc_ocean/anar/augmented-tma/13568_1.png\n",
      "Processing image 67 of 275: /root/ubc_ocean/anar/augmented-tma/13568_2.png\n",
      "Processing image 68 of 275: /root/ubc_ocean/anar/augmented-tma/13568_3.png\n",
      "Processing image 69 of 275: /root/ubc_ocean/anar/augmented-tma/13568_4.png\n",
      "Processing image 70 of 275: /root/ubc_ocean/anar/augmented-tma/13568_5.png\n",
      "Processing image 71 of 275: /root/ubc_ocean/anar/augmented-tma/13568_6.png\n",
      "Processing image 72 of 275: /root/ubc_ocean/anar/augmented-tma/13568_7.png\n",
      "Processing image 73 of 275: /root/ubc_ocean/anar/augmented-tma/13568_8.png\n",
      "Processing image 74 of 275: /root/ubc_ocean/anar/augmented-tma/13568_9.png\n",
      "Processing image 75 of 275: /root/ubc_ocean/anar/augmented-tma/13568_10.png\n",
      "Processing image 76 of 275: /root/ubc_ocean/anar/augmented-tma/17637_1.png\n",
      "Processing image 77 of 275: /root/ubc_ocean/anar/augmented-tma/17637_2.png\n",
      "Processing image 78 of 275: /root/ubc_ocean/anar/augmented-tma/17637_3.png\n",
      "Processing image 79 of 275: /root/ubc_ocean/anar/augmented-tma/17637_4.png\n",
      "Processing image 80 of 275: /root/ubc_ocean/anar/augmented-tma/17637_5.png\n",
      "Processing image 81 of 275: /root/ubc_ocean/anar/augmented-tma/17637_6.png\n",
      "Processing image 82 of 275: /root/ubc_ocean/anar/augmented-tma/17637_7.png\n",
      "Processing image 83 of 275: /root/ubc_ocean/anar/augmented-tma/17637_8.png\n",
      "Processing image 84 of 275: /root/ubc_ocean/anar/augmented-tma/17637_9.png\n",
      "Processing image 85 of 275: /root/ubc_ocean/anar/augmented-tma/17637_10.png\n",
      "Processing image 86 of 275: /root/ubc_ocean/anar/augmented-tma/21020_1.png\n",
      "Processing image 87 of 275: /root/ubc_ocean/anar/augmented-tma/21020_2.png\n",
      "Processing image 88 of 275: /root/ubc_ocean/anar/augmented-tma/21020_3.png\n",
      "Processing image 89 of 275: /root/ubc_ocean/anar/augmented-tma/21020_4.png\n",
      "Processing image 90 of 275: /root/ubc_ocean/anar/augmented-tma/21020_5.png\n",
      "Processing image 91 of 275: /root/ubc_ocean/anar/augmented-tma/21020_6.png\n",
      "Processing image 92 of 275: /root/ubc_ocean/anar/augmented-tma/21020_7.png\n",
      "Processing image 93 of 275: /root/ubc_ocean/anar/augmented-tma/21020_8.png\n",
      "Processing image 94 of 275: /root/ubc_ocean/anar/augmented-tma/21020_9.png\n",
      "Processing image 95 of 275: /root/ubc_ocean/anar/augmented-tma/21020_10.png\n",
      "Processing image 96 of 275: /root/ubc_ocean/anar/augmented-tma/29084_1.png\n",
      "Processing image 97 of 275: /root/ubc_ocean/anar/augmented-tma/29084_2.png\n",
      "Processing image 98 of 275: /root/ubc_ocean/anar/augmented-tma/29084_3.png\n",
      "Processing image 99 of 275: /root/ubc_ocean/anar/augmented-tma/29084_4.png\n",
      "Processing image 100 of 275: /root/ubc_ocean/anar/augmented-tma/29084_5.png\n",
      "Processing image 101 of 275: /root/ubc_ocean/anar/augmented-tma/29084_6.png\n",
      "Processing image 102 of 275: /root/ubc_ocean/anar/augmented-tma/29084_7.png\n",
      "Processing image 103 of 275: /root/ubc_ocean/anar/augmented-tma/29084_8.png\n",
      "Processing image 104 of 275: /root/ubc_ocean/anar/augmented-tma/29084_9.png\n",
      "Processing image 105 of 275: /root/ubc_ocean/anar/augmented-tma/29084_10.png\n",
      "Processing image 106 of 275: /root/ubc_ocean/anar/augmented-tma/31594_1.png\n",
      "Processing image 107 of 275: /root/ubc_ocean/anar/augmented-tma/31594_2.png\n",
      "Processing image 108 of 275: /root/ubc_ocean/anar/augmented-tma/31594_3.png\n",
      "Processing image 109 of 275: /root/ubc_ocean/anar/augmented-tma/31594_4.png\n",
      "Processing image 110 of 275: /root/ubc_ocean/anar/augmented-tma/31594_5.png\n",
      "Processing image 111 of 275: /root/ubc_ocean/anar/augmented-tma/31594_6.png\n",
      "Processing image 112 of 275: /root/ubc_ocean/anar/augmented-tma/31594_7.png\n",
      "Processing image 113 of 275: /root/ubc_ocean/anar/augmented-tma/31594_8.png\n",
      "Processing image 114 of 275: /root/ubc_ocean/anar/augmented-tma/31594_9.png\n",
      "Processing image 115 of 275: /root/ubc_ocean/anar/augmented-tma/31594_10.png\n",
      "Processing image 116 of 275: /root/ubc_ocean/anar/augmented-tma/35565_1.png\n",
      "Processing image 117 of 275: /root/ubc_ocean/anar/augmented-tma/35565_2.png\n",
      "Processing image 118 of 275: /root/ubc_ocean/anar/augmented-tma/35565_3.png\n",
      "Processing image 119 of 275: /root/ubc_ocean/anar/augmented-tma/35565_4.png\n",
      "Processing image 120 of 275: /root/ubc_ocean/anar/augmented-tma/35565_5.png\n",
      "Processing image 121 of 275: /root/ubc_ocean/anar/augmented-tma/35565_6.png\n",
      "Processing image 122 of 275: /root/ubc_ocean/anar/augmented-tma/35565_7.png\n",
      "Processing image 123 of 275: /root/ubc_ocean/anar/augmented-tma/35565_8.png\n",
      "Processing image 124 of 275: /root/ubc_ocean/anar/augmented-tma/35565_9.png\n",
      "Processing image 125 of 275: /root/ubc_ocean/anar/augmented-tma/35565_10.png\n",
      "Processing image 126 of 275: /root/ubc_ocean/anar/augmented-tma/36302_1.png\n",
      "Processing image 127 of 275: /root/ubc_ocean/anar/augmented-tma/36302_2.png\n",
      "Processing image 128 of 275: /root/ubc_ocean/anar/augmented-tma/36302_3.png\n",
      "Processing image 129 of 275: /root/ubc_ocean/anar/augmented-tma/36302_4.png\n",
      "Processing image 130 of 275: /root/ubc_ocean/anar/augmented-tma/36302_5.png\n",
      "Processing image 131 of 275: /root/ubc_ocean/anar/augmented-tma/36302_6.png\n",
      "Processing image 132 of 275: /root/ubc_ocean/anar/augmented-tma/36302_7.png\n",
      "Processing image 133 of 275: /root/ubc_ocean/anar/augmented-tma/36302_8.png\n",
      "Processing image 134 of 275: /root/ubc_ocean/anar/augmented-tma/36302_9.png\n",
      "Processing image 135 of 275: /root/ubc_ocean/anar/augmented-tma/36302_10.png\n",
      "Processing image 136 of 275: /root/ubc_ocean/anar/augmented-tma/36583_1.png\n",
      "Processing image 137 of 275: /root/ubc_ocean/anar/augmented-tma/36583_2.png\n",
      "Processing image 138 of 275: /root/ubc_ocean/anar/augmented-tma/36583_3.png\n",
      "Processing image 139 of 275: /root/ubc_ocean/anar/augmented-tma/36583_4.png\n",
      "Processing image 140 of 275: /root/ubc_ocean/anar/augmented-tma/36583_5.png\n",
      "Processing image 141 of 275: /root/ubc_ocean/anar/augmented-tma/36583_6.png\n",
      "Processing image 142 of 275: /root/ubc_ocean/anar/augmented-tma/36583_7.png\n",
      "Processing image 143 of 275: /root/ubc_ocean/anar/augmented-tma/36583_8.png\n",
      "Processing image 144 of 275: /root/ubc_ocean/anar/augmented-tma/36583_9.png\n",
      "Processing image 145 of 275: /root/ubc_ocean/anar/augmented-tma/36583_10.png\n",
      "Processing image 146 of 275: /root/ubc_ocean/anar/augmented-tma/36783_1.png\n",
      "Processing image 147 of 275: /root/ubc_ocean/anar/augmented-tma/36783_2.png\n",
      "Processing image 148 of 275: /root/ubc_ocean/anar/augmented-tma/36783_3.png\n",
      "Processing image 149 of 275: /root/ubc_ocean/anar/augmented-tma/36783_4.png\n",
      "Processing image 150 of 275: /root/ubc_ocean/anar/augmented-tma/36783_5.png\n",
      "Processing image 151 of 275: /root/ubc_ocean/anar/augmented-tma/36783_6.png\n",
      "Processing image 152 of 275: /root/ubc_ocean/anar/augmented-tma/36783_7.png\n",
      "Processing image 153 of 275: /root/ubc_ocean/anar/augmented-tma/36783_8.png\n",
      "Processing image 154 of 275: /root/ubc_ocean/anar/augmented-tma/36783_9.png\n",
      "Processing image 155 of 275: /root/ubc_ocean/anar/augmented-tma/36783_10.png\n",
      "Processing image 156 of 275: /root/ubc_ocean/anar/augmented-tma/37385_1.png\n",
      "Processing image 157 of 275: /root/ubc_ocean/anar/augmented-tma/37385_2.png\n",
      "Processing image 158 of 275: /root/ubc_ocean/anar/augmented-tma/37385_3.png\n",
      "Processing image 159 of 275: /root/ubc_ocean/anar/augmented-tma/37385_4.png\n",
      "Processing image 160 of 275: /root/ubc_ocean/anar/augmented-tma/37385_5.png\n",
      "Processing image 161 of 275: /root/ubc_ocean/anar/augmented-tma/37385_6.png\n",
      "Processing image 162 of 275: /root/ubc_ocean/anar/augmented-tma/37385_7.png\n",
      "Processing image 163 of 275: /root/ubc_ocean/anar/augmented-tma/37385_8.png\n",
      "Processing image 164 of 275: /root/ubc_ocean/anar/augmented-tma/37385_9.png\n",
      "Processing image 165 of 275: /root/ubc_ocean/anar/augmented-tma/37385_10.png\n",
      "Processing image 166 of 275: /root/ubc_ocean/anar/augmented-tma/40864_1.png\n",
      "Processing image 167 of 275: /root/ubc_ocean/anar/augmented-tma/40864_2.png\n",
      "Processing image 168 of 275: /root/ubc_ocean/anar/augmented-tma/40864_3.png\n",
      "Processing image 169 of 275: /root/ubc_ocean/anar/augmented-tma/40864_4.png\n",
      "Processing image 170 of 275: /root/ubc_ocean/anar/augmented-tma/40864_5.png\n",
      "Processing image 171 of 275: /root/ubc_ocean/anar/augmented-tma/40864_6.png\n",
      "Processing image 172 of 275: /root/ubc_ocean/anar/augmented-tma/40864_7.png\n",
      "Processing image 173 of 275: /root/ubc_ocean/anar/augmented-tma/40864_8.png\n",
      "Processing image 174 of 275: /root/ubc_ocean/anar/augmented-tma/40864_9.png\n",
      "Processing image 175 of 275: /root/ubc_ocean/anar/augmented-tma/40864_10.png\n",
      "Processing image 176 of 275: /root/ubc_ocean/anar/augmented-tma/41368_1.png\n",
      "Processing image 177 of 275: /root/ubc_ocean/anar/augmented-tma/41368_2.png\n",
      "Processing image 178 of 275: /root/ubc_ocean/anar/augmented-tma/41368_3.png\n",
      "Processing image 179 of 275: /root/ubc_ocean/anar/augmented-tma/41368_4.png\n",
      "Processing image 180 of 275: /root/ubc_ocean/anar/augmented-tma/41368_5.png\n",
      "Processing image 181 of 275: /root/ubc_ocean/anar/augmented-tma/41368_6.png\n",
      "Processing image 182 of 275: /root/ubc_ocean/anar/augmented-tma/41368_7.png\n",
      "Processing image 183 of 275: /root/ubc_ocean/anar/augmented-tma/41368_8.png\n",
      "Processing image 184 of 275: /root/ubc_ocean/anar/augmented-tma/41368_9.png\n",
      "Processing image 185 of 275: /root/ubc_ocean/anar/augmented-tma/41368_10.png\n",
      "Processing image 186 of 275: /root/ubc_ocean/anar/augmented-tma/41586_1.png\n",
      "Processing image 187 of 275: /root/ubc_ocean/anar/augmented-tma/41586_2.png\n",
      "Processing image 188 of 275: /root/ubc_ocean/anar/augmented-tma/41586_3.png\n",
      "Processing image 189 of 275: /root/ubc_ocean/anar/augmented-tma/41586_4.png\n",
      "Processing image 190 of 275: /root/ubc_ocean/anar/augmented-tma/41586_5.png\n",
      "Processing image 191 of 275: /root/ubc_ocean/anar/augmented-tma/41586_6.png\n",
      "Processing image 192 of 275: /root/ubc_ocean/anar/augmented-tma/41586_7.png\n",
      "Processing image 193 of 275: /root/ubc_ocean/anar/augmented-tma/41586_8.png\n",
      "Processing image 194 of 275: /root/ubc_ocean/anar/augmented-tma/41586_9.png\n",
      "Processing image 195 of 275: /root/ubc_ocean/anar/augmented-tma/41586_10.png\n",
      "Processing image 196 of 275: /root/ubc_ocean/anar/augmented-tma/42857_1.png\n",
      "Processing image 197 of 275: /root/ubc_ocean/anar/augmented-tma/42857_2.png\n",
      "Processing image 198 of 275: /root/ubc_ocean/anar/augmented-tma/42857_3.png\n",
      "Processing image 199 of 275: /root/ubc_ocean/anar/augmented-tma/42857_4.png\n",
      "Processing image 200 of 275: /root/ubc_ocean/anar/augmented-tma/42857_5.png\n",
      "Processing image 201 of 275: /root/ubc_ocean/anar/augmented-tma/42857_6.png\n",
      "Processing image 202 of 275: /root/ubc_ocean/anar/augmented-tma/42857_7.png\n",
      "Processing image 203 of 275: /root/ubc_ocean/anar/augmented-tma/42857_8.png\n",
      "Processing image 204 of 275: /root/ubc_ocean/anar/augmented-tma/42857_9.png\n",
      "Processing image 205 of 275: /root/ubc_ocean/anar/augmented-tma/42857_10.png\n",
      "Processing image 206 of 275: /root/ubc_ocean/anar/augmented-tma/44603_1.png\n",
      "Processing image 207 of 275: /root/ubc_ocean/anar/augmented-tma/44603_2.png\n",
      "Processing image 208 of 275: /root/ubc_ocean/anar/augmented-tma/44603_3.png\n",
      "Processing image 209 of 275: /root/ubc_ocean/anar/augmented-tma/44603_4.png\n",
      "Processing image 210 of 275: /root/ubc_ocean/anar/augmented-tma/44603_5.png\n",
      "Processing image 211 of 275: /root/ubc_ocean/anar/augmented-tma/44603_6.png\n",
      "Processing image 212 of 275: /root/ubc_ocean/anar/augmented-tma/44603_7.png\n",
      "Processing image 213 of 275: /root/ubc_ocean/anar/augmented-tma/44603_8.png\n",
      "Processing image 214 of 275: /root/ubc_ocean/anar/augmented-tma/44603_9.png\n",
      "Processing image 215 of 275: /root/ubc_ocean/anar/augmented-tma/44603_10.png\n",
      "Processing image 216 of 275: /root/ubc_ocean/anar/augmented-tma/47035_1.png\n",
      "Processing image 217 of 275: /root/ubc_ocean/anar/augmented-tma/47035_2.png\n",
      "Processing image 218 of 275: /root/ubc_ocean/anar/augmented-tma/47035_3.png\n",
      "Processing image 219 of 275: /root/ubc_ocean/anar/augmented-tma/47035_4.png\n",
      "Processing image 220 of 275: /root/ubc_ocean/anar/augmented-tma/47035_5.png\n",
      "Processing image 221 of 275: /root/ubc_ocean/anar/augmented-tma/47035_6.png\n",
      "Processing image 222 of 275: /root/ubc_ocean/anar/augmented-tma/47035_7.png\n",
      "Processing image 223 of 275: /root/ubc_ocean/anar/augmented-tma/47035_8.png\n",
      "Processing image 224 of 275: /root/ubc_ocean/anar/augmented-tma/47035_9.png\n",
      "Processing image 225 of 275: /root/ubc_ocean/anar/augmented-tma/47035_10.png\n",
      "Processing image 226 of 275: /root/ubc_ocean/anar/augmented-tma/48734_1.png\n",
      "Processing image 227 of 275: /root/ubc_ocean/anar/augmented-tma/48734_2.png\n",
      "Processing image 228 of 275: /root/ubc_ocean/anar/augmented-tma/48734_3.png\n",
      "Processing image 229 of 275: /root/ubc_ocean/anar/augmented-tma/48734_4.png\n",
      "Processing image 230 of 275: /root/ubc_ocean/anar/augmented-tma/48734_5.png\n",
      "Processing image 231 of 275: /root/ubc_ocean/anar/augmented-tma/48734_6.png\n",
      "Processing image 232 of 275: /root/ubc_ocean/anar/augmented-tma/48734_7.png\n",
      "Processing image 233 of 275: /root/ubc_ocean/anar/augmented-tma/48734_8.png\n",
      "Processing image 234 of 275: /root/ubc_ocean/anar/augmented-tma/48734_9.png\n",
      "Processing image 235 of 275: /root/ubc_ocean/anar/augmented-tma/48734_10.png\n",
      "Processing image 236 of 275: /root/ubc_ocean/anar/augmented-tma/50932_1.png\n",
      "Processing image 237 of 275: /root/ubc_ocean/anar/augmented-tma/50932_2.png\n",
      "Processing image 238 of 275: /root/ubc_ocean/anar/augmented-tma/50932_3.png\n",
      "Processing image 239 of 275: /root/ubc_ocean/anar/augmented-tma/50932_4.png\n",
      "Processing image 240 of 275: /root/ubc_ocean/anar/augmented-tma/50932_5.png\n",
      "Processing image 241 of 275: /root/ubc_ocean/anar/augmented-tma/50932_6.png\n",
      "Processing image 242 of 275: /root/ubc_ocean/anar/augmented-tma/50932_7.png\n",
      "Processing image 243 of 275: /root/ubc_ocean/anar/augmented-tma/50932_8.png\n",
      "Processing image 244 of 275: /root/ubc_ocean/anar/augmented-tma/50932_9.png\n",
      "Processing image 245 of 275: /root/ubc_ocean/anar/augmented-tma/50932_10.png\n",
      "Processing image 246 of 275: /root/ubc_ocean/anar/augmented-tma/53655_1.png\n",
      "Processing image 247 of 275: /root/ubc_ocean/anar/augmented-tma/53655_2.png\n",
      "Processing image 248 of 275: /root/ubc_ocean/anar/augmented-tma/53655_3.png\n",
      "Processing image 249 of 275: /root/ubc_ocean/anar/augmented-tma/53655_4.png\n",
      "Processing image 250 of 275: /root/ubc_ocean/anar/augmented-tma/53655_5.png\n",
      "Processing image 251 of 275: /root/ubc_ocean/anar/augmented-tma/53655_6.png\n",
      "Processing image 252 of 275: /root/ubc_ocean/anar/augmented-tma/53655_7.png\n",
      "Processing image 253 of 275: /root/ubc_ocean/anar/augmented-tma/53655_8.png\n",
      "Processing image 254 of 275: /root/ubc_ocean/anar/augmented-tma/53655_9.png\n",
      "Processing image 255 of 275: /root/ubc_ocean/anar/augmented-tma/53655_10.png\n",
      "Processing image 256 of 275: /root/ubc_ocean/anar/augmented-tma/57696_1.png\n",
      "Processing image 257 of 275: /root/ubc_ocean/anar/augmented-tma/57696_2.png\n",
      "Processing image 258 of 275: /root/ubc_ocean/anar/augmented-tma/57696_3.png\n",
      "Processing image 259 of 275: /root/ubc_ocean/anar/augmented-tma/57696_4.png\n",
      "Processing image 260 of 275: /root/ubc_ocean/anar/augmented-tma/57696_5.png\n",
      "Processing image 261 of 275: /root/ubc_ocean/anar/augmented-tma/57696_6.png\n",
      "Processing image 262 of 275: /root/ubc_ocean/anar/augmented-tma/57696_7.png\n",
      "Processing image 263 of 275: /root/ubc_ocean/anar/augmented-tma/57696_8.png\n",
      "Processing image 264 of 275: /root/ubc_ocean/anar/augmented-tma/57696_9.png\n",
      "Processing image 265 of 275: /root/ubc_ocean/anar/augmented-tma/57696_10.png\n",
      "Processing image 266 of 275: /root/ubc_ocean/anar/augmented-tma/61797_1.png\n",
      "Processing image 267 of 275: /root/ubc_ocean/anar/augmented-tma/61797_2.png\n",
      "Processing image 268 of 275: /root/ubc_ocean/anar/augmented-tma/61797_3.png\n",
      "Processing image 269 of 275: /root/ubc_ocean/anar/augmented-tma/61797_4.png\n",
      "Processing image 270 of 275: /root/ubc_ocean/anar/augmented-tma/61797_5.png\n",
      "Processing image 271 of 275: /root/ubc_ocean/anar/augmented-tma/61797_6.png\n",
      "Processing image 272 of 275: /root/ubc_ocean/anar/augmented-tma/61797_7.png\n",
      "Processing image 273 of 275: /root/ubc_ocean/anar/augmented-tma/61797_8.png\n",
      "Processing image 274 of 275: /root/ubc_ocean/anar/augmented-tma/61797_9.png\n",
      "Processing image 275 of 275: /root/ubc_ocean/anar/augmented-tma/61797_10.png\n"
     ]
    }
   ],
   "source": [
    "images_dir = '/root/ubc_ocean/'\n",
    "\n",
    "# Increase the maximum number of pixels PIL can process\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Load a pre-trained model for feature extraction\n",
    "model = timm.create_model('resnet101', pretrained=True, num_classes=0)\n",
    "model.eval()\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Function to check if the tile has tissue present\n",
    "def is_tissue_present(tile, area_threshold=0.55, low_saturation_threshold=20):   # 55% tissue\n",
    "    hsv = cv2.cvtColor(tile, cv2.COLOR_RGB2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "    _, high_sat = cv2.threshold(s, low_saturation_threshold, 255, cv2.THRESH_BINARY)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    tissue_mask = cv2.dilate(high_sat, kernel, iterations=2)\n",
    "    tissue_mask = cv2.erode(tissue_mask, kernel, iterations=2)\n",
    "    tissue_ratio = np.sum(tissue_mask > 0) / (tile_size * tile_size)\n",
    "    return tissue_ratio > area_threshold\n",
    "\n",
    "# Function to extract features from a tile\n",
    "def extract_features(tile, model, transform):\n",
    "    tile = Image.fromarray(tile)\n",
    "    tile = transform(tile).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        features = model(tile)\n",
    "    return features.squeeze(0).numpy()\n",
    "\n",
    "# Function to process a patch of the image\n",
    "def process_patch(patch, model, transform):\n",
    "    if is_tissue_present(patch):\n",
    "        features = extract_features(patch, model, transform)\n",
    "        return features\n",
    "    return None\n",
    "\n",
    "# Define the size for the tiles\n",
    "tile_size = 224\n",
    "\n",
    "all_patch_features = {}\n",
    "\n",
    "# Process each image, extract tiles, extract features, and store them\n",
    "total_images = len(combined_tma)\n",
    "for index, row in combined_tma.iterrows():\n",
    "    tile_features = []  # List to hold the features for the current image\n",
    "\n",
    "    # Get the image path\n",
    "    image_name = row['path']  # Adjust based on your DataFrame structure\n",
    "    image_path = os.path.join(images_dir, image_name)\n",
    "\n",
    "    # Print the current status\n",
    "    print(f\"Processing image {index + 1} of {total_images}: {image_path}\")\n",
    "\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            for y in range(0, img.height, tile_size):\n",
    "                for x in range(0, img.width, tile_size):\n",
    "                    # Read the patch\n",
    "                    patch = img.crop((x, y, x + tile_size, y + tile_size))\n",
    "                    patch = np.array(patch)  # Convert PIL Image to NumPy array\n",
    "\n",
    "                    # Process the patch\n",
    "                    features = process_patch(patch, model, transform)\n",
    "                    if features is not None:\n",
    "                        tile_features.append(features)\n",
    "\n",
    "        # Store the extracted features and the label in the slide_features_part1 dictionary\n",
    "        all_patch_features[image_name] = {\n",
    "            'features': tile_features,\n",
    "            'label': row['label']\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_name}: {e}\")\n",
    "\n",
    "# Final save\n",
    "with open('/root/ubc_ocean/anar/extracted-features/combinedtma_224px_resnet101_275.pkl', 'wb') as f:\n",
    "    pickle.dump(all_patch_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/root/ubc_ocean/anar/extracted-features/combinedtma_224px_resnet101_275.pkl', 'rb') as f:\n",
    "    all_patch_features = pickle.load(f)\n",
    "    \n",
    "len(all_patch_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training (not works)\n",
    "##### Anyway, for MIL classifier to perform well, having a diverse set is critical, augmenting the same image in 10 ways and extracting features would still result in relatively similar features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train balance: {'CC': 44, 'MC': 44, 'HGSC': 44, 'EC': 44, 'LGSC': 44}\n",
      "Validation balance: {'HGSC': 5, 'MC': 5, 'LGSC': 5, 'CC': 5, 'EC': 5}\n",
      "Test balance: {'LGSC': 6, 'CC': 6, 'EC': 6, 'HGSC': 6, 'MC': 6}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "# Set a fixed random state for reproducibility\n",
    "random_state = 33\n",
    "\n",
    "# Convert slide_features to a suitable format\n",
    "data = [(features['features'], features['label']) for path, features in all_patch_features.items()]\n",
    "\n",
    "# Organize data by labels\n",
    "data_by_label = defaultdict(list)\n",
    "for features, label in data:\n",
    "    data_by_label[label].append((features, label))\n",
    "\n",
    "# Split data for each label into train, validation, and test\n",
    "train_data = []\n",
    "val_data = []\n",
    "test_data = []\n",
    "\n",
    "for label, label_data in data_by_label.items():\n",
    "    # Split data for this label into train and test with a fixed random state\n",
    "    train_val_label_data, test_label_data = train_test_split(label_data, test_size=0.10, random_state=random_state)\n",
    "    \n",
    "    # Split train data into train and validation with a fixed random state\n",
    "    train_label_data, val_label_data = train_test_split(train_val_label_data, test_size=0.1, random_state=random_state)  # 0.25 x 0.8 = 0.2 of original\n",
    "    \n",
    "    # Append split data to respective sets\n",
    "    train_data.extend(train_label_data)\n",
    "    val_data.extend(val_label_data)\n",
    "    test_data.extend(test_label_data)\n",
    "\n",
    "# Shuffle the datasets\n",
    "random.seed(random_state)\n",
    "random.shuffle(train_data)\n",
    "random.shuffle(val_data)\n",
    "random.shuffle(test_data)\n",
    "\n",
    "# Function to check balance in each set\n",
    "def check_balance(dataset):\n",
    "    label_counts = defaultdict(int)\n",
    "    for _, label in dataset:\n",
    "        label_counts[label] += 1\n",
    "    return dict(label_counts)\n",
    "\n",
    "# Display balance of each set\n",
    "print(\"Train balance:\", check_balance(train_data))\n",
    "print(\"Validation balance:\", check_balance(val_data))\n",
    "print(\"Test balance:\", check_balance(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from label strings to integers\n",
    "unique_labels = sorted(set(label for _, label in data))\n",
    "label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "class MILDataset(Dataset):\n",
    "    def __init__(self, data, label_to_idx):\n",
    "        self.data = data\n",
    "        self.label_to_idx = label_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature_vectors, label = self.data[idx]\n",
    "        label_idx = self.label_to_idx[label]  # Convert label to integer\n",
    "        return torch.tensor(feature_vectors), torch.tensor(label_idx, dtype=torch.float32)\n",
    "\n",
    "# Create Datasets for train, validation, and test\n",
    "train_dataset = MILDataset(train_data, label_to_idx)\n",
    "val_dataset = MILDataset(val_data, label_to_idx)\n",
    "test_dataset = MILDataset(test_data, label_to_idx)\n",
    "\n",
    "# Create DataLoaders for each set\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "class AttentionMIL(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super(AttentionMIL, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Softmax(dim=0)\n",
    "        )\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)  # num_classes instead of 1\n",
    "\n",
    "    def forward(self, bag):\n",
    "        h = torch.relu(self.fc1(bag))\n",
    "        a = self.attention(h)\n",
    "        v = torch.sum(a * h, dim=0)\n",
    "        y = self.classifier(v)  # Remove softmax here; output raw scores\n",
    "        return y, a\n",
    "\n",
    "# Number of unique classes\n",
    "num_classes = len(unique_labels)\n",
    "\n",
    "model = AttentionMIL(input_dim=2048, hidden_dim=256, num_classes=num_classes)\n",
    "loss_function = nn.CrossEntropyLoss()  # CrossEntropyLoss for multiclass\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "\n",
    "# Early Stopping Parameters\n",
    "best_val_loss = float('inf')\n",
    "patience = 4\n",
    "patience_counter = 0\n",
    "\n",
    "# Model Training with Validation\n",
    "num_epochs = 15\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    # Training loop\n",
    "    for bags, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        bags = bags.squeeze(0)  # Remove the extra dimension from bags\n",
    "        labels = labels.squeeze(0).long()  # Remove extra dimension and ensure long type for labels\n",
    "        output, _ = model(bags)\n",
    "        loss = loss_function(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 0)\n",
    "        train_total += 1\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_accuracy = 100 * train_correct / train_total\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for bags, labels in val_loader:\n",
    "            bags = bags.squeeze(0)\n",
    "            labels = labels.squeeze(0).long()\n",
    "            output, _ = model(bags)\n",
    "            loss = loss_function(output, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 0)\n",
    "            val_total += 1\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    val_loss /= len(val_loader)\n",
    "    \n",
    "    # Step the scheduler\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Stopping early due to no improvement in validation loss.\")\n",
    "        break\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Validation Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for bags, labels in test_loader:\n",
    "        output, _ = model(bags.squeeze(0))\n",
    "        _, predicted_labels = torch.max(output, 0)  # Get the index of the max log-probability\n",
    "        predictions.append(predicted_labels.item())  # Append scalar value\n",
    "        true_labels.append(labels.squeeze(0).item())  # Append scalar value\n",
    "\n",
    "# Convert lists to arrays for metric calculation\n",
    "predictions = np.array(predictions)\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "precision = precision_score(true_labels, predictions, average='macro', zero_division=1)\n",
    "recall = recall_score(true_labels, predictions, average='macro')\n",
    "f1 = f1_score(true_labels, predictions, average='macro')\n",
    "\n",
    "# Print the metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "\n",
    "# Use idx_to_label to map numeric predictions back to label names\n",
    "predicted_labels = [idx_to_label[int(idx)] for idx in predictions]\n",
    "true_label_names = [idx_to_label[int(idx)] for idx in true_labels]\n",
    "\n",
    "# Now predicted_labels and true_label_names contain the label names\n",
    "print(predicted_labels)\n",
    "print(true_label_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Baku",
   "language": "python",
   "name": "baku"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
